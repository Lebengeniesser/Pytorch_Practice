{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtLPyagU7V9l1UHjucKkNa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lebengeniesser/Pytorch_Practice/blob/master/Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O9R9heotTv7",
        "outputId": "eea0847f-c69c-460e-8596-62c8521a0236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "#Tensor\n",
        "#array이나 matrix와 매우 유사한 특수한 자료구조이다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력, 그리고 모델의 매개변수들을 부호화(encode)한다.\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "data = [[1,2],[3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "np_array=np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "\n",
        "x_ones = torch.ones_like(x_data)\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
        "\n",
        "#random 또는 constant값을 사용하기:\n",
        "shape = (2,3,) #2행 3열 \n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")\n",
        "\n",
        "#텐서의 속성(Attribute)\n",
        "\n",
        "tensor = torch.rand(3,4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "\n",
        "#텐서 연산(Operation)\n",
        "#전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형대구, 임의 샘플링(random sampling)등, 100가지 이상의 ㅇ텐서 연선확인가능\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")\n",
        "\n",
        "tensor = torch.ones(4,4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1]=0\n",
        "print(tensor) #행 전체를 표시할떄는 [:, ]  or [..., ]로 사용가능\n",
        "\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)\n",
        "#두 텐서 간의 행렬 곱을 계산합니다.\n",
        "y1 = tensor @ tensor.T\n",
        "print(\"y1: \", y1)\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "print(\"y2: \", y2)\n",
        "y3=torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "print(\"y3:\",y3)\n",
        "\n",
        "#요소별 곱을 계산한다.\n",
        "z1 = tensor * tensor\n",
        "print(\"z1:\",z1)\n",
        "z2 = tensor.mul(tensor)\n",
        "z3=torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)\n",
        "print(\"z3:\",z3)\n",
        "\n",
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item,type(agg_item))\n",
        "\n",
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "#수정이 되므로 사용을 권장하지 않음\n",
        "\n",
        "#Numpy 변환(Bridge)\n",
        "#CPU상의 텐서와 NumPy배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다.\n",
        "t = torch.ones(5)\n",
        "print(f\"t: {t} \\n\") #tensor자료구조는 앞에 tensor라고 뜨고 넘파이는 자동으로 리스트형태 띔\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")\n",
        "\n",
        "np.add(n, 1, out=n) \n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\") #메모리가 연결되어있어 같이 더해짐\n",
        "\n",
        "#NumPy 배열을 텐서로 변환하기\n",
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "np.add(n, 1, out=n) #numpy로 수정했는데 같이 수정됨\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")\n"
      ]
    }
  ]
}